{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKp5a4cU/tUyxE79xAyMR/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eunterko/MAT421/blob/main/ModuleC_Section_19_1_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Chapter 19: Root Finding**"
      ],
      "metadata": {
        "id": "FeqAA5Qp1DkI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *19.1 Root Finding Problem Statement*"
      ],
      "metadata": {
        "id": "apBVCm591IW9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The problem statement for root finding is: when given some function f(x), find the values x_r such that f(x_r) = 0. These x_r are called roots, or zeros. As a simple example, let's find the root of a polynomial, x^3 - 2. (we will use the fsolve function from scipy for this, although we will talk more about using fsolve later)"
      ],
      "metadata": {
        "id": "GSf1knJW1deo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import fsolve\n",
        "\n",
        "f = lambda x: x**3 - 2\n",
        "x_r = fsolve(f, 2)\n",
        "print(\"x_r =\", x_r)\n",
        "\n",
        "result = f(x_r)\n",
        "print(\"f(x_r) =\", result)"
      ],
      "metadata": {
        "id": "qvWEjXJ01ItZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75952471-9357-4a6b-dbd4-44463c1c7961"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_r = [1.25992105]\n",
            "f(x_r) = [0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *19.2 Tolerance*"
      ],
      "metadata": {
        "id": "b-PCK_A41JEO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For finding roots of functions, we will have to consider how accurate we want the roots to be. Tolerance is the amount of error that we are willing to accept in the accuracy of the roots we find."
      ],
      "metadata": {
        "id": "AaXkHO661jio"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are a few different ways that we can define tolerance, based on the situation or root-finding method we are using. One possible measure for tolerance could be the absolute value of the function, |f(x)|. If we are using an iterative loop to find the root however, the absolute value of the difference between two consecutive possible roots, |x_(i+1) - x_i|, could be more useful. The different measures of tolerance have their individual benefits and issues, so they will have to selected carefully."
      ],
      "metadata": {
        "id": "uTi_ZJAr6AwQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *19.3 Bisection Method*"
      ],
      "metadata": {
        "id": "j04kYtJ-1JkR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bisection method is based on the intermediate value theorem: if f(x) is continuous between points x = a and x = b, and the signs of a and b are opposite, there must be some c in a<c<b such that f(c) = 0. Essentially, if we know a function is continuous and it goes from negative to positive or positive to negative, then it must pass through zero."
      ],
      "metadata": {
        "id": "Y1L5PDIq1oVK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the bisection method, we use the intermediate value theorem to limit the boundaries around the root, until we can find it. The process is as follows: given some function f(x), we will calculate the midpoint m between a and b. If this midpoint m gives f(m) = 0 within our wanted tolerance, we have found a root. Otherwise, if f(m) > 0 or f(m) < 0, we replace either a or b with m, and repeat the process. "
      ],
      "metadata": {
        "id": "W5P7KdYe8EBB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define a function to carry out this method, and use it to solve the same polynomial root problem from above."
      ],
      "metadata": {
        "id": "ZN-Udjxf9VJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def bisection_solve(f,a,b,tol):\n",
        "    \n",
        "    if np.sign(f(a)) == np.sign(f(b)):\n",
        "        print('Root not found')\n",
        "        return None\n",
        "    \n",
        "    m = (a+b)/2\n",
        "    \n",
        "    if np.abs(f(m)) < tol:\n",
        "        return m\n",
        "    elif np.sign(f(a)) == np.sign(f(m)):\n",
        "        return bisection_solve(f, m, b, tol)\n",
        "    elif np.sign(f(b)) == np.sign(f(m)):\n",
        "        return bisection_solve(f, a, m, tol)\n",
        "\n",
        "f = lambda x: x**3 - 2\n",
        "x_r = bisection_solve(f,0,3,1)\n",
        "print(\"x_r with high tolerance is\", x_r)\n",
        "x_r = bisection_solve(f,0,3,0.01)\n",
        "print(\"x_r with low tolerance is\", x_r)"
      ],
      "metadata": {
        "id": "cX9xLGY-1JwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76e363ff-f7ee-4949-f3f2-4bcd3fd901b5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_r with high tolerance is 1.125\n",
            "x_r with low tolerance is 1.259765625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From here, we can see the effect that tolerance has on our root-finding function."
      ],
      "metadata": {
        "id": "QX8azx3u_jq6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *19.4 Newton-Raphson Method*"
      ],
      "metadata": {
        "id": "FX9k0M771J74"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rather than relying on the intermediate value theorem, the Newton-Raphson method uses the first two terms of a Taylor expansion of our function f(x) to iterate and find roots. We start from some guess of the root, x_0, and then iterate using Newton steps. These steps are given from"
      ],
      "metadata": {
        "id": "rRgarkGW1vbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# x_(i+1) = x_i - f(x_i) / f'(x_i)"
      ],
      "metadata": {
        "id": "RWwuxHTo1KFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The primary benefit of the Newton-Raphson method over the bisection method is that Newton-Raphson converges to the root x_r much faster in general, as long as our guess x_0 is relatively close to x_r. The flipside of this, of course, is that if our guess x_0 is not close to x_r, the Newton-Raphson method might not be as effective. Additionally, since the Newton-Raphson method involves the derivative of f(x), there is the potential for further complications. For example, if the derivative at a point is close to zero, the Newton step will be much larger and could take us further away from the root we want. Also, the behavior of the deriviative of f(x) might lead us to a different root than the x_r we are looking for. It will be important to keep all these drawbacks in mind when using this method, and determining when to use it over the bisection method."
      ],
      "metadata": {
        "id": "mwVToSziBDsL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's define a function to carry out the Newton-Raphson method, and once again use it to solve the same polynomial root problem."
      ],
      "metadata": {
        "id": "cT8FDO8uCXVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def newton_raphson(f,f_prime,x_0,tol):\n",
        "    if abs(f(x_0)) < tol:\n",
        "        return x_0\n",
        "    else:\n",
        "        return newton_raphson(f,f_prime,x_0-f(x_0)/f_prime(x_0),tol)\n",
        "\n",
        "f = lambda x: x**3 - 2\n",
        "f_prime = lambda x: 3*x**2\n",
        "x_r = newton_raphson(f,f_prime,5,0.01)\n",
        "print(\"x_r =\", x_r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8K_eozFQCf05",
        "outputId": "73474dc8-14d5-4f7c-8de1-7c9190a85650"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_r = 1.2599462296275672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *19.5 Root Finding in Python*"
      ],
      "metadata": {
        "id": "m11pEEuj1KOg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As previously mentioned, Python has the f_solve function in scipy.optimize to help find roots. Similar to the Newton-Raphson method, we will need some initial guess when using f_solve. Returning to our simple polynomial once more, we have"
      ],
      "metadata": {
        "id": "dcTXMRPi10qs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import fsolve\n",
        "\n",
        "f = lambda x: x**3 - 2\n",
        "x_r = fsolve(f, 2)\n",
        "print(\"x_r =\", x_r)"
      ],
      "metadata": {
        "id": "ZH7yUV__1KZN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5daf2d21-a74e-4648-dede-04aec2fb6176"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_r = [1.25992105]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's also look at a more complicated example, to see the ease and convenience of f_solve:"
      ],
      "metadata": {
        "id": "L9JZLlIZPZK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import fsolve\n",
        "\n",
        "f = lambda x: np.sin(x) - np.tan(x**2) + x**3 - np.exp(-2*x)\n",
        "x_r = fsolve(f, [0,1])\n",
        "print(\"x_r =\", x_r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vprWeZtCPfQs",
        "outputId": "8e7ea349-6b72-4d1b-e4b7-3c46c5c05fec"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_r = [0.51461185 1.03696285]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we have seen, there are several different ways to solve the root-finding problem statement, each with respective pros and cons. "
      ],
      "metadata": {
        "id": "w9Hn3lq8QJWe"
      }
    }
  ]
}